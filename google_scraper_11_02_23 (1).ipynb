{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ebb92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image quality solved\n",
    "#cartoon image solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc07da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\local_disk_D\\anaconda\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.0a2) or chardet (3.0.4)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Selenium helps you use this executable to automate Chrome\n",
    "from multiprocessing.sharedctypes import Value\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime as dt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4e87ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of Image -> usa\n",
      "Number of Image -> 20\n",
      "Making directory: usa\n",
      "Found 1\n",
      "Found 2\n",
      "Found 3\n",
      "Found 4\n",
      "Found 5\n",
      "Found 6\n",
      "Found 7\n",
      "Found 8\n",
      "Found 9\n",
      "Found 10\n",
      "Found 11\n",
      "Found 12\n",
      "Found 13\n",
      "Found 14\n",
      "Found 15\n",
      "Found 16\n",
      "Found 17\n",
      "Found 18\n",
      "Found 19\n",
      "Found 20\n",
      "{'https://images7.alphacoders.com/687/687665.jpg', 'https://images.shiksha.ws/mediadata/images/articles/1400484392php7qGdJ02.jpg', 'https://static.javatpoint.com/fullformpages/images/usa.jpg', 'https://www.usnews.com/object/image/0000016f-8c62-d408-a9ef-9ffe94a60000/200115bcusaprofile-editorial.usa.profile.jpg?update-time=1578608368142&size=superhero-medium', 'https://c8.alamy.com/comp/ERNY24/usa-map-in-blue-and-red-colors-ERNY24.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Map_of_USA_States_with_names_white.svg/640px-Map_of_USA_States_with_names_white.svg.png', 'https://geology.com/world/the-united-states-of-america-map.gif', 'https://www.nationsonline.org/maps/USA-map.jpg', 'https://m.media-amazon.com/images/I/71xRXqkEHyL._SL1380_.jpg', 'https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg', 'https://www.toppersbulletin.com/wp-content/uploads/2021/12/How-Many-States-are-in-USA.jpg', 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRXsyRC1D_mvxvDZAHdZo_89q6Xej4hp5fRRA&usqp=CAU', 'https://m.media-amazon.com/images/I/71pFOeSBrHL.jpg', 'https://www.whereig.com/usa/maps/usa-states-us-map.jpg', 'https://workpermit.com/sites/default/files/styles/large/public/5357522048_35c1db3008_z.jpg?itok=BHRrY-sO', 'https://images.unsplash.com/photo-1471306224500-6d0d218be372?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxzZWFyY2h8M3x8dXNhfGVufDB8fDB8fA%3D%3D&w=1000&q=80', 'https://www.kidsworldfun.com/images/usa/USA.jpg', 'https://upload.wikimedia.org/wikipedia/commons/a/a4/Map_of_USA_with_state_and_territory_names_2.png', 'https://cdn.britannica.com/85/183785-050-77A0FDB5/The-United-States.jpg', 'https://oec.world/api/image?slug=country&memberSlug=usa&size=splash'}\n",
      "The image: images/nottingham_forest/usa/1.jpg downloaded successfully at 21:15:15.\n",
      "The image: images/nottingham_forest/usa/2.jpg downloaded successfully at 21:15:16.\n",
      "The image: images/nottingham_forest/usa/3.jpg downloaded successfully at 21:15:17.\n",
      "The image: images/nottingham_forest/usa/4.jpg downloaded successfully at 21:15:17.\n",
      "The image: images/nottingham_forest/usa/5.jpg downloaded successfully at 21:15:17.\n",
      "Unable to download image from Google Photos due to\n",
      ": cannot write mode LA as JPEG\n",
      "Unable to download image from Google Photos due to\n",
      ": cannot write mode P as JPEG\n",
      "The image: images/nottingham_forest/usa/8.jpg downloaded successfully at 21:15:21.\n",
      "The image: images/nottingham_forest/usa/9.jpg downloaded successfully at 21:15:21.\n",
      "Unable to download image from Google Photos due to\n",
      ": cannot identify image file <_io.BytesIO object at 0x00000296B6F80A40>\n",
      "The image: images/nottingham_forest/usa/11.jpg downloaded successfully at 21:15:22.\n",
      "Unable to download image from Google Photos due to\n",
      ": cannot write mode P as JPEG\n",
      "The image: images/nottingham_forest/usa/13.jpg downloaded successfully at 21:15:22.\n",
      "The image: images/nottingham_forest/usa/14.jpg downloaded successfully at 21:15:23.\n",
      "The image: images/nottingham_forest/usa/15.jpg downloaded successfully at 21:15:23.\n",
      "The image: images/nottingham_forest/usa/16.jpg downloaded successfully at 21:15:26.\n",
      "The image: images/nottingham_forest/usa/17.jpg downloaded successfully at 21:15:26.\n",
      "The image: images/nottingham_forest/usa/18.jpg downloaded successfully at 21:15:27.\n",
      "Unable to download image from Google Photos due to\n",
      ": image file is truncated (35 bytes not processed)\n",
      "The image: images/nottingham_forest/usa/20.jpg downloaded successfully at 21:15:29.\n",
      "CPU times: total: 3.03 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time #for check cell procssing time\n",
    "#Download the driver from chromedriver website for relevant OS i.e. MAC, Windows, Debian, etc.\n",
    "\n",
    "PATH = 'C:/Users/91735/Downloads/chromedriver_win32/chromedriver.exe'\n",
    "wd = webdriver.Chrome(executable_path=PATH)\n",
    "\n",
    "\n",
    "\n",
    "def get_images_from_google(wd, delay, max_images, url):\n",
    "    def scroll_down(wd):\n",
    "        wd.execute_script(\"window.scrollBy(0,document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    url = url\n",
    "    wd.get(url)\n",
    "    wd.maximize_window()\n",
    "    \n",
    "    image_urls = set()\n",
    "    skips = 0\n",
    "    c = 0\n",
    "    cur_len = 0\n",
    "    while True:\n",
    "        if len(image_urls)==cur_len:\n",
    "            c+=1\n",
    "        else:\n",
    "            c=0\n",
    "        if c==6 or len(image_urls)==max_images:\n",
    "            break\n",
    "        scroll_down(wd)\n",
    "        thumbnails = wd.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "        \n",
    "        for img in thumbnails[len(image_urls) + skips:max_images]:\n",
    "            try:\n",
    "                img.click()\n",
    "                time.sleep(delay)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            images = wd.find_elements(By.CLASS_NAME, \"n3VNCb\")\n",
    "            for image in images:\n",
    "                if image.get_attribute('src') in image_urls:\n",
    "                    max_images += 1\n",
    "                    skips += 1\n",
    "                    break\n",
    "                    \n",
    "                if image.get_attribute('src') and 'http' in image.get_attribute('src'):\n",
    "                    image_urls.add(image.get_attribute('src'))\n",
    "                    print(f\"Found {len(image_urls)}\")\n",
    "        cur_len = len(image_urls)         \n",
    "    #print(image_urls)\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def download_image(down_path, url, file_name, image_type='JPEG',\n",
    "                   verbose=True):\n",
    "    try:\n",
    "        time = dt.now()\n",
    "        curr_time = time.strftime('%H:%M:%S')\n",
    "        #Content of the image will be a url\n",
    "        header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36', \"Upgrade-Insecure-Requests\": \"1\",\"DNT\": \"1\",\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\"Accept-Language\": \"en-US,en;q=0.5\",\"Accept-Encoding\": \"gzip, deflate\"}\n",
    "        img_content = requests.get(url,headers=header,timeout=3).content\n",
    "        #Get the bytes IO of the image\n",
    "        img_file = io.BytesIO(img_content)\n",
    "        #Stores the file in memory and convert to image file using Pillow\n",
    "        image = Image.open(img_file)\n",
    "        file_pth = down_path + file_name\n",
    "\n",
    "        with open(file_pth, 'wb') as file:\n",
    "            image.save(file, image_type,quality=95)\n",
    "\n",
    "        if verbose == True:\n",
    "            print(f'The image: {file_pth} downloaded successfully at {curr_time}.')\n",
    "    except Exception as e:\n",
    "        print(f'Unable to download image from Google Photos due to\\n: {str(e)}')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Google search URLS\n",
    "    ij=input(\"Content of Image -> \")\n",
    "    tk=ij.replace(\" \",\"+\")\n",
    "    max_images=int(input(\"Number of Image -> \"))\n",
    "    #print(ij)\n",
    "    google_urls = ['https://www.google.com/search?q='+tk+'&tbm=isch&ved=2ahUKEwi73fyn3sj3AhUD-4UKHSjyBpAQ2-cCegQIABAA&oq=alex&gs_lcp=CgNpbWcQARgAMgcIIxDvAxAnMgcIIxDvAxAnMgoIABCxAxCDARBDMgQIABBDMgQIABBDMgQIABBDMggIABCABBCxAzIECAAQQzIICAAQgAQQsQMyCAgAEIAEELEDOgUIABCABDoECAAQGDoLCAAQgAQQsQMQgwE6CAgAELEDEIMBOgcIABCxAxBDUKIHWJwLYLwUaABwAHgAgAFLiAHIApIBATWYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=g_VzYvuPJIP2lwSo5JuACQ&bih=969&biw=1920&rlz=1C1CHBF_en-GBGB924GB924&hl=en']\n",
    "    # Labels for the players\n",
    "    labels = [tk]\n",
    "    \n",
    "    # Check the length of the lists\n",
    "    if len(google_urls) != len(labels):\n",
    "        raise ValueError('The length of the url list does not match the labels list.')\n",
    "\n",
    "    player_path = 'images/nottingham_forest/'\n",
    "    # Make the directory if it doesn't exist\n",
    "    for lbl in labels:\n",
    "        if not os.path.exists(player_path + lbl):\n",
    "            print(f'Making directory: {str(lbl)}')\n",
    "            os.makedirs(player_path+lbl)\n",
    "\n",
    "    for url_current, lbl in zip(google_urls, labels):\n",
    "        urls = get_images_from_google(wd, 2,max_images, url_current)\n",
    "        # Once we have added our urls to empty set then \n",
    "        for i, url in enumerate(urls):\n",
    "            download_image(down_path=f'images/nottingham_forest/{lbl}/', \n",
    "                        url=url, \n",
    "                        file_name=str(i+1)+ '.jpg',\n",
    "                  verbose=True)\n",
    "    wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31f1b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
